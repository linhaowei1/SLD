{"id": "454bac3e-c235-4b3b-aff6-e53b6c4d588d_migrant_3", "code": "import numpy as np\n\n# EVOLVE-BLOCK-START\n\"\"\"\nNormalized\u2010quadratic scaling\u2010law model for LLM hyperparameters.\n\nWe fit log(loss) as a second\u2010order polynomial in the normalized log\u2010domain\nof the four inputs [lr, batch_size, data_size, non_embedding_param_size].\nThis yields 15 parameters:\n  - 1 intercept\n  - 4 linear terms\n  - 4 squared terms\n  - 6 pairwise interaction terms\nWe solve via closed\u2010form ridge regression in the log\u2010loss domain with a\ntiny adaptive regularization for numerical stability and no penalty on\nthe intercept.\n\"\"\"\n\n# Known global log\u2010range of each feature for normalization\n# Columns: [learning_rate, batch_size, data_size, non_embedding_param_size]\n_LOG_F_MINS = np.log(np.array([\n    1.2e-4,   # lr min\n    16.0,     # batch size min\n    4e9,      # data size min\n    2.14e8    # non\u2010embedding param size min\n], dtype=float))\n_LOG_F_MAXS = np.log(np.array([\n    2.2e-2,   # lr max\n    4096.0,   # batch size max\n    1e11,     # data size max\n    1e9       # non\u2010embedding param size max\n], dtype=float))\n_LOG_F_RANGES = _LOG_F_MAXS - _LOG_F_MINS  # for normalization to [0,1]\n\ndef _build_design_matrix(logX_norm):\n    \"\"\"\n    Build a design matrix \u03a6 for a normalized quadratic polynomial:\n      Columns = [1,\n                 xi for each feature i,\n                 xi^2 for each feature i,\n                 xi * xj for all i<j]\n    where xi = log\u2010normalized feature i.\n    Returns shape (N, 15).\n    \"\"\"\n    N, F = logX_norm.shape\n    # total params: 1 intercept + F linear + F squared + F*(F-1)/2 interactions\n    P = 1 + F + F + (F*(F-1))//2\n    Phi = np.empty((N, P), dtype=float)\n    # intercept\n    Phi[:, 0] = 1.0\n    # linear terms\n    Phi[:, 1:1+F] = logX_norm\n    # squared terms\n    start_sq = 1 + F\n    Phi[:, start_sq:start_sq+F] = logX_norm**2\n    # pairwise interactions\n    idx = start_sq + F\n    for i in range(F):\n        for j in range(i+1, F):\n            Phi[:, idx] = logX_norm[:, i] * logX_norm[:, j]\n            idx += 1\n    return Phi\n\ndef scaling_law_func(data_points, params):\n    \"\"\"\n    Predict LM loss from hyperparameters via the learned\n    normalized\u2010quadratic scaling law.\n\n    Args:\n      data_points: array\u2010like of shape (N,4) with columns\n                   [lr, batch_size, data_size, non_embedding_param_size]\n      params:      1D array of length 15\n\n    Returns:\n      preds: array of shape (N,) of predicted LM loss values\n    \"\"\"\n    X = np.asarray(data_points, dtype=float)\n    # support single\u2010point input\n    if X.ndim == 1:\n        X = X.reshape(1, -1)\n    if X.shape != (X.shape[0], 4):\n        raise ValueError(f\"Expected data_points shape (N,4), got {X.shape}\")\n    # avoid non\u2010positive values\n    X = np.clip(X, 1e-12, None)\n    # log\u2010transform & normalize to [0,1]\n    logX = np.log(X)\n    logX_norm = (logX - _LOG_F_MINS) / _LOG_F_RANGES\n    logX_norm = np.clip(logX_norm, 0.0, 1.0)\n    # build design matrix\n    Phi = _build_design_matrix(logX_norm)  # (N,15)\n    p = np.asarray(params, dtype=float).ravel()\n    if p.size != Phi.shape[1]:\n        raise ValueError(f\"Expected {Phi.shape[1]} parameters, got {p.size}\")\n    # predict in log\u2010domain and exponentiate\n    log_pred = Phi.dot(p)\n    return np.exp(log_pred)\n\ndef fit_scaling_law(data_points, loss_values):\n    \"\"\"\n    Fit the normalized\u2010quadratic scaling law via closed\u2010form ridge regression.\n\n    Args:\n      data_points: array\u2010like of shape (N,4)\n      loss_values: array\u2010like of shape (N,)\n\n    Returns:\n      params: 1D array of length 15 of learned coefficients in log\u2010loss domain\n    \"\"\"\n    X = np.asarray(data_points, dtype=float)\n    y = np.asarray(loss_values, dtype=float).ravel()\n    # support single\u2010point input\n    if X.ndim == 1:\n        X = X.reshape(1, -1)\n    if X.shape[0] != y.shape[0]:\n        raise ValueError(\"Number of data points and loss values must match.\")\n    if X.shape[1] != 4:\n        raise ValueError(f\"Expected data_points shape (N,4), got {X.shape}\")\n    # clamp positives\n    X = np.clip(X, 1e-12, None)\n    y = np.clip(y, 1e-12, None)\n    # log\u2010transform & normalize features\n    logX = np.log(X)\n    logX_norm = (logX - _LOG_F_MINS) / _LOG_F_RANGES\n    logX_norm = np.clip(logX_norm, 0.0, 1.0)\n    # design matrix\n    Phi = _build_design_matrix(logX_norm)  # (N,15)\n    # target in log\u2010domain\n    logy = np.log(y)\n    # normal equations\n    A = Phi.T.dot(Phi)      # (15,15)\n    b = Phi.T.dot(logy)     # (15,)\n    # adaptive ridge: tiny regularization on non\u2010intercept terms\n    P = A.shape[0]\n    ridge = 1e-6 * (np.trace(A) / P)\n    # add ridge to diagonal except intercept\n    diag_idx = np.diag_indices(P)\n    A[diag_idx] += ridge\n    A[0,0] -= ridge\n    # solve\n    params = np.linalg.solve(A, b)\n    return params\n# EVOLVE-BLOCK-END", "language": "python", "parent_id": "454bac3e-c235-4b3b-aff6-e53b6c4d588d", "generation": 6, "timestamp": 1754806559.1057897, "iteration_found": 0, "metrics": {"nmse": 0.009529812593006361, "nmae": 0.10319057777458805, "r2": 0.9904701874069937, "combined_score": 0.990560147432864}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"nmse": 0.3868934976149482, "nmae": 0.7363985304629478, "r2": 0.6131065023850518, "combined_score": 0.7210358990936997}, "island": 3, "migrant": true}, "artifacts_json": null, "artifact_dir": null}