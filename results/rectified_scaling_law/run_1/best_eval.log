--- Running Evaluation for Program: results/rectified_scaling_law/run_1/best/best_program.py ---
Inferred Task: rectified_scaling_law

--- Final Test Results ---
  Normalized MSE (NMSE): 0.011947
  Normalized MAE (NMAE): 0.091263
  R-squared (R2):        0.988053
  Combined Score:        0.988194

Fitted parameters for 42 group(s):
  - Group '('MBZUAI/LaMini-GPT-124M', 'flan')': [   0.       13.3465 3656.8847    0.1404]
  - Group '('MBZUAI/LaMini-GPT-774M', 'flan')': [   0.        9.7827 4033.0799    0.1255]
  - Group '('cerebras/Cerebras-GPT-256M', 'flan')': [   0.        5.7236 1987.8345    0.0711]
  - Group '('cerebras/Cerebras-GPT-1.3B', 'flan')': [  0.       4.0888 463.7436   0.0599]
  - Group '('facebook/bart-base', 'flan')': [   0.       10.2109 1658.9736    0.1232]
  - Group '('facebook/bart-large', 'flan')': [  0.       5.8688 425.1657   0.087 ]
  - Group '('facebook/opt-1.3b', 'flan')': [  0.       3.4619 362.894    0.0559]
  - Group '('facebook/opt-350m', 'flan')': [   0.        6.0713 2202.2484    0.0855]
  - Group '('facebook/opt-6.7b', 'flan')': [ 0.      2.2406 30.6384  0.0194]
  - Group '('gpt2', 'flan')': [   0.       14.9831 4423.9647    0.1481]
  - Group '('t5-base', 'flan')': [  0.       4.0188 674.0801   0.064 ]
  - Group '('t5-small', 'flan')': [  0.       4.5289 564.0216   0.063 ]
  - Group '('google/mt5-base', 'flan')': [  0.       4.9524 279.8978   0.0711]
  - Group '('google/mt5-large', 'flan')': [  0.       3.7404 302.5668   0.0592]
  - Group '('MBZUAI/LaMini-GPT-124M', 'gigaword')': [    0.7116   152.1087 12784.8011     0.4418]
  - Group '('MBZUAI/LaMini-GPT-774M', 'gigaword')': [   0.489    53.1965 8184.92      0.3527]
  - Group '('cerebras/Cerebras-GPT-256M', 'gigaword')': [   0.       11.4814 3334.7437    0.1723]
  - Group '('cerebras/Cerebras-GPT-1.3B', 'gigaword')': [   0.        6.9812 1631.184     0.128 ]
  - Group '('facebook/bart-base', 'gigaword')': [   0.6484  145.9408 6983.6737    0.4506]
  - Group '('facebook/bart-large', 'gigaword')': [   0.4555   65.3146 4285.4698    0.3764]
  - Group '('facebook/opt-1.3b', 'gigaword')': [   0.3508   11.3309 1931.6722    0.2037]
  - Group '('facebook/opt-350m', 'gigaword')': [   0.4746   29.1942 3524.2846    0.2949]
  - Group '('facebook/opt-6.7b', 'gigaword')': [   1.6339    1.8515 5573.5998    0.1921]
  - Group '('gpt2', 'gigaword')': [   0.4373   37.4013 5362.2781    0.3081]
  - Group '('t5-base', 'gigaword')': [0.4161 1.8205 0.     0.1672]
  - Group '('t5-small', 'gigaword')': [  0.5394   2.2622 140.6162   0.1957]
  - Group '('google/mt5-base', 'gigaword')': [  0.       3.6688 584.9629   0.0376]
  - Group '('google/mt5-large', 'gigaword')': [   0.        4.3367 2405.3548    0.0549]
  - Group '('MBZUAI/LaMini-GPT-124M', 'wikiword')': [  0.       4.3117 526.6341   0.0763]
  - Group '('MBZUAI/LaMini-GPT-774M', 'wikiword')': [  0.       2.997  149.4223   0.0576]
  - Group '('cerebras/Cerebras-GPT-256M', 'wikiword')': [  0.       4.8032 227.7082   0.0762]
  - Group '('cerebras/Cerebras-GPT-1.3B', 'wikiword')': [  0.       3.4634 456.944    0.0584]
  - Group '('facebook/bart-base', 'wikiword')': [  1.3405  24.4251 839.0982   0.367 ]
  - Group '('facebook/bart-large', 'wikiword')': [0.7229 2.6242 0.     0.1083]
  - Group '('facebook/opt-1.3b', 'wikiword')': [ 0.      2.3746 48.2022  0.0428]
  - Group '('facebook/opt-350m', 'wikiword')': [ 0.      3.2775 31.9181  0.0565]
  - Group '('facebook/opt-6.7b', 'wikiword')': [  0.884    1.3794 152.9766   0.091 ]
  - Group '('gpt2', 'wikiword')': [  0.       4.4047 381.0466   0.0784]
  - Group '('t5-base', 'wikiword')': [  0.       2.4003 324.3772   0.0502]
  - Group '('t5-small', 'wikiword')': [  0.       3.0217 380.1465   0.0582]
  - Group '('google/mt5-base', 'wikiword')': [  0.       5.6232 422.0457   0.109 ]
  - Group '('google/mt5-large', 'wikiword')': [ 0.      4.082  90.7209  0.0819]
--------------------------
